---
title: "Examining the citation and altmetric advantage of bioRxiv preprints: bioRxiv analysis"
---

### Load libraries

```{r results='hide'}

library(tidyverse)
library(lubridate)
library(lme4)

```

### How do our methodologies for discovering preprint-published article links overlap?

```{r results='hide'}

# Load the preprint-published links for each methodology
# Crossref relationshiop
CR <- read_csv("data/raw/preprints_published_articles_cr.csv") %>% 
  pull(PREPRINT_DOI)
# bioRxiv website
BIO <- read_csv("data/raw/preprints_published_articles_bio.csv") %>% 
  pull(PREPRINT_DOI)
# Scopus fuzzy matching
SCP <- read_csv("data/raw/preprints_published_articles_scp.csv") %>% 
  pull(PREPRINT_DOI)

# Calculate the intersection between all possible permutations
CR_BIO_SCP <- length(intersect(intersect(CR,BIO), SCP))
CR_BIO <- length(intersect(CR,BIO)) - CR_BIO_SCP
CR_SCP <- length(intersect(CR,SCP)) - CR_BIO_SCP
BIO_SCP <- length(intersect(BIO,SCP)) - CR_BIO_SCP
CR <- length(CR) - CR_BIO_SCP - CR_BIO - CR_SCP
BIO <- length(BIO) - CR_BIO_SCP - CR_BIO - BIO_SCP
SCP <- length(SCP) - CR_BIO_SCP - CR_SCP - BIO_SCP

# Calculate the fit for Venn diagram
fit <-  c("CR" = CR, "BIO" = BIO, "SCP" = SCP, 
          "CR&BIO" = CR_BIO, "CR&SCP" = CR_SCP, 
          "BIO&SCP" = BIO_SCP, "CR&BIO&SCP" = CR_BIO_SCP)

# Save overlaps to csv
enframe(fit) %>% 
  rename(ENTITIES = name, OVERLAP = value) %>%
  write_csv("data/analysis/matching_overlap.csv")

# Remove redundant variables
rm(CR_BIO_SCP, CR_BIO, CR_SCP, BIO_SCP, CR, BIO, SCP, fit)

```

### How have deposition of biorXiv preprints and publication outcomes changed over time?

```{r results='hide'}

# Join preprints dataset to dataset of preprints-published article links.
# Aggregate sample size and percentage published at year and month level
read_csv("data/raw/preprints.csv") %>%
  mutate(YEAR_MON = format(PREPRINT_POSTED_DATE, "%Y-%m"),
         YEAR = format(PREPRINT_POSTED_DATE, "%Y")) %>%
  left_join(read_csv("data/raw/preprints_published_articles.csv")) %>%
  mutate(IS_PUBLISHED = case_when(
    is.na(ARTICLE_DOI) ~ 0,
    !is.na(ARTICLE_DOI) ~ 1
  )) %>%
  group_by(YEAR, YEAR_MON) %>%
  summarize(
    DEPOSITED = n(),
    PCT_PUBLISHED = sum(IS_PUBLISHED)/n()*100) %>%
  write_csv(path="data/analysis/monthly_preprints.csv")

```

### What was the mean and median time between preprint submission and journal publication?

```{r results='hide'}

# Join preprints and articles, calculate difference in dates between preprint
# posted date and article published date
read_csv("data/raw/preprints.csv") %>%
  inner_join(read_csv("data/raw/articles.csv") %>% 
  filter(TYPE == "Deposited"), by="PREPRINT_DOI") %>%
  mutate(publication_time = interval(date(PREPRINT_POSTED_DATE),
                                     date(ARTICLE_CREATED_DATE)) %/% days(1)) %>%
  summarize(mean_publication_time = mean(publication_time),
            median_publication_time = median(publication_time))

```

### How many citations were there to bioRxiv-deposited and control articles in total?

```{r results='hide'}

# Citations to bioRxiv-deposited articles
read_csv("data/raw/articles.csv") %>% 
  filter(TYPE == "Deposited") %>% 
  inner_join(read_csv("data/raw/citing_articles.csv"), 
             by=c("ARTICLE_DOI" = "CITED_ARTICLE_DOI")) %>%
  summarise(n = n())

# Citations to control articles
read_csv("data/raw/articles.csv") %>% 
  filter(TYPE == "Control") %>% 
  inner_join(read_csv("data/raw/citing_articles.csv"), 
             by=c("ARTICLE_DOI" = "CITED_ARTICLE_DOI")) %>%
  summarise(n = n())

```

# Regression Analysis ----------------------------------------------------------

### Datasets for analysis

```{r}

# Build a summary table of each individual characteristic included in our regression model
article_characteristics <- read_csv("data/analysis/article_characteristics.csv")

# Generate a dataset of paired articles and their relative article characteristics
paired <- article_characteristics %>% filter(TYPE == "Deposited") %>%
  inner_join(article_characteristics %>% filter(TYPE == "Control"), by="PREPRINT_DOI")

```

### Summary statistics and tests for differences between characteristics

Continuous variables: Wilcoxon signed-rank test

```{r}

# IF (no need to calculate paired differences/tests)
article_characteristics %>%
  group_by(TYPE) %>%
  summarize(median = median(IF, na.rm = T),
            q25 = quantile(IF, 0.25, na.rm = T),
            q75 = quantile(IF, 0.75, na.rm = T),
            min = min(IF, na.rm = T),
            max = max(IF, na.rm = T))

# Author Count
article_characteristics %>%
  group_by(TYPE) %>%
  summarize(median = median(AUTHOR_CNT, na.rm = T),
            q25 = quantile(AUTHOR_CNT, 0.25, na.rm = T),
            q75 = quantile(AUTHOR_CNT, 0.75, na.rm = T),
            min = min(AUTHOR_CNT, na.rm = T),
            max = max(AUTHOR_CNT, na.rm = T))

paired %>%
  mutate(diff = AUTHOR_CNT.x - AUTHOR_CNT.y) %>%
  summarize(median = median(diff, na.rm = T),
            q25 = quantile(diff, 0.25, na.rm = T),
            q75 = quantile(diff, 0.75, na.rm = T),
            min = min(diff, na.rm = T),
            max = max(diff, na.rm = T))

test <- wilcox.test(paired$AUTHOR_CNT.x, 
            paired$AUTHOR_CNT.y, 
            alternative = c("two.sided"),
            paired=TRUE)
Z <- qnorm(test$p.value/2)

# First Author Age
article_characteristics %>%
  group_by(TYPE) %>%
  summarize(median = median(FIRST_AUTHOR_AGE, na.rm = T),
            q25 = quantile(FIRST_AUTHOR_AGE, 0.25, na.rm = T),
            q75 = quantile(FIRST_AUTHOR_AGE, 0.75, na.rm = T),
            min = min(FIRST_AUTHOR_AGE, na.rm = T),
            max = max(FIRST_AUTHOR_AGE, na.rm = T))

paired %>%
  mutate(diff = FIRST_AUTHOR_AGE.x - FIRST_AUTHOR_AGE.y) %>%
  summarize(median = median(diff, na.rm = T),
            q25 = quantile(diff, 0.25, na.rm = T),
            q75 = quantile(diff, 0.75, na.rm = T),
            min = min(diff, na.rm = T),
            max = max(diff, na.rm = T))

test <- wilcox.test(paired$FIRST_AUTHOR_AGE.x, 
            paired$FIRST_AUTHOR_AGE.y, 
            alternative = c("two.sided"),
            paired=TRUE)
Z <- qnorm(test$p.value/2)

# Last Author Age
article_characteristics %>%
  group_by(TYPE) %>%
  summarize(median = median(LAST_AUTHOR_AGE, na.rm = T),
            q25 = quantile(LAST_AUTHOR_AGE, 0.25, na.rm = T),
            q75 = quantile(LAST_AUTHOR_AGE, 0.75, na.rm = T),
            min = min(LAST_AUTHOR_AGE, na.rm = T),
            max = max(LAST_AUTHOR_AGE, na.rm = T))

paired %>%
  mutate(diff = LAST_AUTHOR_AGE.x - LAST_AUTHOR_AGE.y) %>%
  summarize(median = median(diff, na.rm = T),
            q25 = quantile(diff, 0.25, na.rm = T),
            q75 = quantile(diff, 0.75, na.rm = T),
            min = min(diff, na.rm = T),
            max = max(diff, na.rm = T))

test <- wilcox.test(paired$LAST_AUTHOR_AGE.x, 
            paired$LAST_AUTHOR_AGE.y, 
            alternative = c("two.sided"),
            paired=TRUE)
Z <- qnorm(test$p.value/2)

```

Categorical variables: Contigency tables and McNemars Test

```{r}

# IS_OA
table(paired$IS_OA.x, paired$IS_OA.y)
mcnemar.test(table(paired$IS_OA.x, paired$IS_OA.y))

# FIRST_AUTHOR_IS_US
table(paired$FIRST_AUTHOR_IS_US.x, paired$FIRST_AUTHOR_IS_US.y)
mcnemar.test(table(paired$FIRST_AUTHOR_IS_US.x, paired$FIRST_AUTHOR_IS_US.y))

# LAST_AUTHOR_IS_US
table(paired$LAST_AUTHOR_IS_US.x, paired$LAST_AUTHOR_IS_US.y)
mcnemar.test(table(paired$LAST_AUTHOR_IS_US.x, paired$LAST_AUTHOR_IS_US.y))

# FIRST_AUTHOR_IS_FEMALE
table(paired$FIRST_AUTHOR_IS_FEMALE.x, paired$FIRST_AUTHOR_IS_FEMALE.y)
mcnemar.test(table(paired$FIRST_AUTHOR_IS_FEMALE.x, paired$FIRST_AUTHOR_IS_FEMALE.y))

# LAST_AUTHOR_IS_FEMALE
table(paired$LAST_AUTHOR_IS_FEMALE.x, paired$LAST_AUTHOR_IS_FEMALE.y)
mcnemar.test(table(paired$LAST_AUTHOR_IS_FEMALE.x, paired$LAST_AUTHOR_IS_FEMALE.y))

# FIRST_AUTHOR_TOP100_INSTITUTE
table(paired$FIRST_AUTHOR_TOP100_INSTITUTE.x, paired$FIRST_AUTHOR_TOP100_INSTITUTE.y)
mcnemar.test(table(paired$FIRST_AUTHOR_TOP100_INSTITUTE.x, paired$FIRST_AUTHOR_TOP100_INSTITUTE.y))

# LAST_AUTHOR_TOP100_INSTITUTE
table(paired$LAST_AUTHOR_TOP100_INSTITUTE.x, paired$LAST_AUTHOR_TOP100_INSTITUTE.y)
mcnemar.test(table(paired$LAST_AUTHOR_TOP100_INSTITUTE.x, paired$LAST_AUTHOR_TOP100_INSTITUTE.y))


```

### Summary of outcome variables

```{r}

# 12 month citations

# Summary statistics
read_csv("data/analysis/article_monthly_citations.csv") %>% 
  filter(CITATION_INTERVAL == 12) %>%
  group_by(TYPE) %>%
  summarize(n = n(),
            mean = mean(CUMULATIVE_CITATIONS),
            median = median(CUMULATIVE_CITATIONS),
            iqr25 = quantile(CUMULATIVE_CITATIONS, 0.25),
            iqr75 = quantile(CUMULATIVE_CITATIONS, 0.75))

# Paired differences
paired <- read_csv("data/analysis/article_monthly_citations.csv") %>% 
  filter(CITATION_INTERVAL == 12) %>%
  filter(TYPE == "Deposited") %>%
  inner_join(read_csv("data/analysis/article_monthly_citations.csv") %>% 
  filter(CITATION_INTERVAL == 12) %>%
  filter(TYPE == "Control"), by = "PREPRINT_DOI")

paired %>%
  mutate(diff = CUMULATIVE_CITATIONS.x - CUMULATIVE_CITATIONS.y) %>%
  group_by(TYPE.x) %>%
  summarize(mean = mean(diff),
            median = median(diff),
            iqr25 = quantile(diff, 0.25),
            iqr75 = quantile(diff, 0.75))

# Wilcoxon test
wilcox.test(paired$CUMULATIVE_CITATIONS.x, 
            paired$CUMULATIVE_CITATIONS.y, 
            alternative = c("two.sided"),
            paired=TRUE)


# 24 month citations

# Summary statistics
read_csv("data/analysis/article_monthly_citations.csv") %>% 
  filter(CITATION_INTERVAL == 24) %>%
  group_by(TYPE) %>%
  summarize(n = n(),
            median = median(CUMULATIVE_CITATIONS),
            iqr25 = quantile(CUMULATIVE_CITATIONS, 0.25),
            iqr75 = quantile(CUMULATIVE_CITATIONS, 0.75))

# Paired differences
paired <- read_csv("data/analysis/article_monthly_citations.csv") %>% 
  filter(CITATION_INTERVAL == 24) %>%
  filter(TYPE == "Deposited") %>%
  inner_join(read_csv("data/analysis/article_monthly_citations.csv") %>% 
  filter(CITATION_INTERVAL == 24) %>%
  filter(TYPE == "Control"), by = "PREPRINT_DOI")

paired %>%
  mutate(diff = CUMULATIVE_CITATIONS.x - CUMULATIVE_CITATIONS.y) %>%
  group_by(TYPE.x) %>%
  summarize(mean = mean(diff),
            median = median(diff),
            iqr25 = quantile(diff, 0.25),
            iqr75 = quantile(diff, 0.75))

# Wilcoxon test
wilcox.test(paired$CUMULATIVE_CITATIONS.x, 
            paired$CUMULATIVE_CITATIONS.y, 
            alternative = c("two.sided"),
            paired=TRUE)

# 36 month citations

# Summary statistics
read_csv("data/analysis/article_monthly_citations.csv") %>% 
  filter(CITATION_INTERVAL == 36) %>%
  group_by(TYPE) %>%
  summarize(n = n(),
            median = median(CUMULATIVE_CITATIONS),
            iqr25 = quantile(CUMULATIVE_CITATIONS, 0.25),
            iqr75 = quantile(CUMULATIVE_CITATIONS, 0.75))

# Paired differences
paired <- read_csv("data/analysis/article_monthly_citations.csv") %>% 
  filter(CITATION_INTERVAL == 36) %>%
  filter(TYPE == "Deposited") %>%
  inner_join(read_csv("data/analysis/article_monthly_citations.csv") %>% 
  filter(CITATION_INTERVAL == 36) %>%
  filter(TYPE == "Control"), by = "PREPRINT_DOI")

paired %>%
  mutate(diff = CUMULATIVE_CITATIONS.x - CUMULATIVE_CITATIONS.y) %>%
  group_by(TYPE.x) %>%
  summarize(mean = mean(diff),
            median = median(diff),
            iqr25 = quantile(diff, 0.25),
            iqr75 = quantile(diff, 0.75))

# Wilcoxon test
wilcox.test(paired$CUMULATIVE_CITATIONS.x, 
            paired$CUMULATIVE_CITATIONS.y, 
            alternative = c("two.sided"),
            paired=TRUE)

# Altmetrics

paired_altmetrics_data <- read_csv("data/raw/article_altmetrics.csv") %>%
  inner_join(article_characteristics, by=c("PREPRINT_DOI", "ARTICLE_DOI")) %>%
  filter(TYPE == "Deposited") %>%
  inner_join(read_csv("data/raw/article_altmetrics.csv") %>%
  inner_join(article_characteristics, by=c("PREPRINT_DOI", "ARTICLE_DOI")) %>%
  filter(TYPE == "Control"), by = "PREPRINT_DOI")

# Tweets

# Summary statistics
read_csv("data/raw/article_altmetrics.csv") %>%
  inner_join(article_characteristics, by=c("PREPRINT_DOI", "ARTICLE_DOI")) %>%
  group_by(TYPE) %>%
  summarize(n = n(),
            mean = mean(ALT_TWEETS),
            median = median(ALT_TWEETS),
            iqr25 = quantile(ALT_TWEETS, 0.25),
            iqr75 = quantile(ALT_TWEETS, 0.75))

# Paired differences
paired_altmetrics_data %>%
  mutate(diff = ALT_TWEETS.x - ALT_TWEETS.y) %>%
  group_by(TYPE.x) %>%
  summarize(mean = mean(diff),
            median = median(diff),
            iqr25 = quantile(diff, 0.25),
            iqr75 = quantile(diff, 0.75))

# Wilcoxon test
wilcox.test(paired_altmetrics_data$ALT_TWEETS.x, 
            paired_altmetrics_data$ALT_TWEETS.y, 
            alternative = c("two.sided"),
            paired=TRUE)

# Blogs

# Summary statistics
read_csv("data/raw/article_altmetrics.csv") %>%
  inner_join(article_characteristics, by=c("PREPRINT_DOI", "ARTICLE_DOI")) %>%
  group_by(TYPE) %>%
  summarize(n = n(),
            mean = mean(ALT_FEEDS),
            median = median(ALT_FEEDS),
            iqr25 = quantile(ALT_FEEDS, 0.25),
            iqr75 = quantile(ALT_FEEDS, 0.75))

# Paired differences
paired_altmetrics_data %>%
  mutate(diff = ALT_FEEDS.x - ALT_FEEDS.y) %>%
  group_by(TYPE.x) %>%
  summarize(mean = mean(diff),
            median = median(diff),
            iqr25 = quantile(diff, 0.25),
            iqr75 = quantile(diff, 0.75))

# Wilcoxon test
wilcox.test(paired_altmetrics_data$ALT_FEEDS.x, 
            paired_altmetrics_data$ALT_FEEDS.y, 
            alternative = c("two.sided"),
            paired=TRUE)

# News

# Summary statistics
read_csv("data/raw/article_altmetrics.csv") %>%
  inner_join(article_characteristics, by=c("PREPRINT_DOI", "ARTICLE_DOI")) %>%
  group_by(TYPE) %>%
  summarize(n = n(),
            mean = mean(ALT_MSM),
            median = median(ALT_MSM),
            iqr25 = quantile(ALT_MSM, 0.25),
            iqr75 = quantile(ALT_MSM, 0.75))

# Paired differences
paired_altmetrics_data %>%
  mutate(diff = ALT_MSM.x - ALT_MSM.y) %>%
  group_by(TYPE.x) %>%
  summarize(mean = mean(diff),
            median = median(diff),
            iqr25 = quantile(diff, 0.25),
            iqr75 = quantile(diff, 0.75))

# Wilcox test
wilcox.test(paired_altmetrics_data$ALT_MSM.x, 
            paired_altmetrics_data$ALT_MSM.y, 
            alternative = c("two.sided"),
            paired=TRUE)

# Summary statistics
read_csv("data/raw/article_altmetrics.csv") %>%
  inner_join(article_characteristics, by=c("PREPRINT_DOI", "ARTICLE_DOI")) %>%
  group_by(TYPE) %>%
  summarize(n = n(),
            mean = mean(ALT_WIKIPEDIA),
            sd = sd(ALT_WIKIPEDIA),
            median = median(ALT_WIKIPEDIA),
            iqr25 = quantile(ALT_WIKIPEDIA, 0.25),
            iqr75 = quantile(ALT_WIKIPEDIA, 0.75))

# Paired differences
paired_altmetrics_data %>%
  mutate(diff = ALT_WIKIPEDIA.x - ALT_WIKIPEDIA.y) %>%
  group_by(TYPE.x) %>%
  summarize(mean = mean(diff),
            median = median(diff),
            iqr25 = quantile(diff, 0.25),
            iqr75 = quantile(diff, 0.75))

# Wilcox test
wilcox.test(paired_altmetrics_data$ALT_WIKIPEDIA.x, 
            paired_altmetrics_data$ALT_WIKIPEDIA.y, 
            alternative = c("two.sided"),
            paired=TRUE)

# Mendeley

# Summary statistics
read_csv("data/raw/article_altmetrics.csv") %>%
  inner_join(article_characteristics, by=c("PREPRINT_DOI", "ARTICLE_DOI")) %>%
  group_by(TYPE) %>%
  summarize(n = n(),
            mean = mean(ALT_MENDELEY),
            median = median(ALT_MENDELEY),
            iqr25 = quantile(ALT_MENDELEY, 0.25),
            iqr75 = quantile(ALT_MENDELEY, 0.75))

# Paired differences
paired_altmetrics_data %>%
  mutate(diff = ALT_MENDELEY.x - ALT_MENDELEY.y) %>%
  group_by(TYPE.x) %>%
  summarize(mean = mean(diff),
            median = median(diff),
            iqr25 = quantile(diff, 0.25),
            iqr75 = quantile(diff, 0.75))

# Wilcox test
wilcox.test(paired_altmetrics_data$ALT_MENDELEY.x, 
            paired_altmetrics_data$ALT_MENDELEY.y, 
            alternative = c("two.sided"),
            paired=TRUE)

```


### Correlation tests between variables

```{r}

library(GGally)

article_characteristics %>%
  select(IF, AUTHOR_CNT, IS_OA, FIRST_AUTHOR_AGE, LAST_AUTHOR_AGE, FIRST_AUTHOR_IS_US, LAST_AUTHOR_IS_US, FIRST_AUTHOR_IS_FEMALE, LAST_AUTHOR_IS_FEMALE, FIRST_AUTHOR_TOP100_INSTITUTE, LAST_AUTHOR_TOP100_INSTITUTE) %>%
  ggpairs() %>%
  print(progress = F)

```

### Load count data and join to characteristics for regression

```{r}

article_altmetrics <- read_csv("data/raw/article_altmetrics.csv")  %>%
  inner_join(article_characteristics, by=c("PREPRINT_DOI", "ARTICLE_DOI")) %>%
  mutate(PREPRINT_DOI = factor(PREPRINT_DOI),
         ARTICLE_DOI = factor(ARTICLE_DOI),
         TYPE = factor(TYPE)) %>%
  dplyr::select(-SOURCETITLE, -ARTICLE_CREATED_DATE) %>%
  group_by(PREPRINT_DOI) %>%
  filter_all(all_vars(all(!is.na(.))))

articles_monthly_citations <- read_csv("data/analysis/article_monthly_citations.csv") %>%
  inner_join(article_characteristics, by=c("PREPRINT_DOI", "ARTICLE_DOI", "TYPE")) %>%
  mutate(PREPRINT_DOI = factor(PREPRINT_DOI),
         ARTICLE_DOI = factor(ARTICLE_DOI),
         TYPE = factor(TYPE)) %>%
  dplyr::select(-SOURCETITLE, -ARTICLE_CREATED_DATE) %>%
  group_by(PREPRINT_DOI) %>%
  filter_all(all_vars(all(!is.na(.))))

```

### Regression Analysis: Citations

#### Reduced Model

```{r}

# Negative binomial model
fit_nb_reduced_citations <- lme4::glmer.nb(CUMULATIVE_CITATIONS ~ TYPE + CITATION_INTERVAL + (1|PREPRINT_DOI), 
                                           nAGQ=0, 
                                           data = articles_monthly_citations)
# Log-transformed models
fit_log_reduced_citations <- lme4::lmer(LOG_CUMULATIVE_CITATIONS ~ TYPE + (1|PREPRINT_DOI), 
                                        REML=F, 
                                        data = articles_monthly_citations)

# Compare AIC - see https://stats.stackexchange.com/questions/48714/prerequisites-for-aic-model-comparison
aic_nb_reduced_citations <- AIC(fit_nb_reduced_citations)
aic_log_reduced_citations <- AIC(fit_log_reduced_citations) + (2*sum(articles_monthly_citations$LOG_CUMULATIVE_CITATIONS))

# Confidence intervals. WARNING: SLOW!!!
confint_nb_reduced_citations_lme <- lme4::confint.merMod(fit_nb_reduced_citations, method="boot", boot.type="basic", nsim= 1000, parallel="snow", ncpus=4)

# Assess multicollinearity (VIF)
meanvif_nb_reduced_citations <- mean(car::vif(fit_nb_reduced_citations))

# Dispersion parameter (theta)
theta_nb_reduced_citations <- getME(fit_nb_reduced_citations, "glmer.nb.theta")

```

#### Full Model

```{r}

# Negative binomial model
fit_nb_full_citations <- lme4::glmer.nb(CUMULATIVE_CITATIONS ~ TYPE * CITATION_INTERVAL + TYPE * IF + AUTHOR_CNT + IS_OA + FIRST_AUTHOR_AGE + LAST_AUTHOR_AGE + FIRST_AUTHOR_IS_US + LAST_AUTHOR_IS_US + FIRST_AUTHOR_IS_FEMALE + LAST_AUTHOR_IS_FEMALE + FIRST_AUTHOR_TOP100_INSTITUTE + LAST_AUTHOR_TOP100_INSTITUTE + (1|PREPRINT_DOI), 
                              nAGQ=0, 
                              data = articles_monthly_citations)
# Log-transformed models
fit_log_full_citations <- lme4::lmer(LOG_CUMULATIVE_CITATIONS ~ TYPE * CITATION_INTERVAL + TYPE * IF + AUTHOR_CNT + IS_OA + FIRST_AUTHOR_AGE + LAST_AUTHOR_AGE + FIRST_AUTHOR_IS_US + LAST_AUTHOR_IS_US + FIRST_AUTHOR_IS_FEMALE + LAST_AUTHOR_IS_FEMALE + FIRST_AUTHOR_TOP100_INSTITUTE + LAST_AUTHOR_TOP100_INSTITUTE + (1|PREPRINT_DOI),
                           REML=F, 
                           data = articles_monthly_citations)

# Compare AIC - see https://stats.stackexchange.com/questions/48714/prerequisites-for-aic-model-comparison
aic_nb_full_citations <- AIC(fit_nb_full_citations)
aic_log_full_citations <- AIC(fit_log_full_citations) + (2*sum(articles_monthly_citations$LOG_CUMULATIVE_CITATIONS))

# Confidence intervals. WARNING: SLOW!!!
confint_nb_full_citations <- confint(fit_nb_full_citations, method="boot", boot.type="basic", nsim= 1000, parallel="snow", ncpus=4)

# Assess multicollinearity (VIF)
meanvif_nb_full_citations <- mean(car::vif(fit_nb_full_citations))

# Dispersion parameter (theta)
theta_nb_full_citations <- getME(fit_nb_full_citations, "glmer.nb.theta")

```

### Regression Analysis: Twitter

#### Reduced Models

```{r}
sa
# Negative binomial model
fit_nb_reduced_tweets <- lme4::glmer.nb(ALT_TWEETS ~ TYPE + (1|PREPRINT_DOI), 
                               nAGQ=0,
                               data = article_altmetrics)
# Log-transformed models
fit_log_reduced_tweets <- lme4::lmer(log(ALT_TWEETS+1) ~ TYPE + (1|PREPRINT_DOI), 
                            REML=F, 
                            data = article_altmetrics)

# Compare AIC - see https://stats.stackexchange.com/questions/48714/prerequisites-for-aic-model-comparison
aic_nb_reduced_tweets <- AIC(fit_nb_reduced_tweets)
aic_log_reduced_tweets <- AIC(fit_log_reduced_tweets) + (2*sum(log(article_altmetrics$ALT_TWEETS+1)))

# Dispersion parameter (theta)
theta_nb_reduced_tweets <- getME(fit_nb_reduced_tweets, "glmer.nb.theta")
```

#### Full Models

```{r}
# Negative binomial model
fit_nb_full_tweets <- lme4::glmer.nb(ALT_TWEETS ~ TYPE * IF + AUTHOR_CNT + IS_OA + FIRST_AUTHOR_AGE + LAST_AUTHOR_AGE + FIRST_AUTHOR_IS_US + LAST_AUTHOR_IS_US + FIRST_AUTHOR_IS_FEMALE + LAST_AUTHOR_IS_FEMALE + FIRST_AUTHOR_TOP100_INSTITUTE + LAST_AUTHOR_TOP100_INSTITUTE + (1|PREPRINT_DOI), 
                              nAGQ=0, 
                              data = article_altmetrics)
# Log-transformed models
fit_log_full_tweets <- lme4::lmer(log(ALT_TWEETS+1) ~ TYPE * IF + AUTHOR_CNT + IS_OA + FIRST_AUTHOR_AGE + LAST_AUTHOR_AGE + FIRST_AUTHOR_IS_US + LAST_AUTHOR_IS_US + FIRST_AUTHOR_IS_FEMALE + LAST_AUTHOR_IS_FEMALE + FIRST_AUTHOR_TOP100_INSTITUTE + LAST_AUTHOR_TOP100_INSTITUTE + (1|PREPRINT_DOI),
                           REML=F, 
                           data = article_altmetrics)

# Compare AIC - see https://stats.stackexchange.com/questions/48714/prerequisites-for-aic-model-comparison
aic_nb_full_tweets <- AIC(fit_nb_full_tweets)
aic_log_full_tweets <- AIC(fit_log_full_tweets) + (2*sum(log(article_altmetrics$ALT_TWEETS+1)))

# Assess multicollinearity (VIF)
vif_nb_full_tweets <- car::vif(fit_nb_full_tweets)
meanvif_nb_full_tweets <- mean(car::vif(fit_nb_full_tweets))

# Dispersion parameter (theta)
theta_nb_full_tweets <- getME(fit_nb_full_tweets, "glmer.nb.theta")
```

### Regression Analysis: Blogs (Feeds)

#### Reduced Models

```{r}
# Negative binomial model
fit_nb_reduced_feeds <- lme4::glmer.nb(ALT_FEEDS ~ TYPE + (1|PREPRINT_DOI), 
                               nAGQ=0, 
                               data = article_altmetrics)
# Log-transformed models
fit_log_reduced_feeds <- lme4::lmer(log(ALT_FEEDS+1) ~ TYPE + (1|PREPRINT_DOI), 
                            REML=F, 
                            data = article_altmetrics)

# Compare AIC - see https://stats.stackexchange.com/questions/48714/prerequisites-for-aic-model-comparison
aic_nb_reduced_feeds <- AIC(fit_nb_reduced_feeds)
aic_log_reduced_feeds <- AIC(fit_log_reduced_feeds) + (2*sum(log(article_altmetrics$ALT_FEEDS+1)))

# Dispersion parameter (theta)
theta_nb_reduced_feeds <- getME(fit_nb_reduced_feeds, "glmer.nb.theta")

```

#### Full Models

```{r}
# Negative binomial model
fit_nb_full_feeds <- lme4::glmer.nb(ALT_FEEDS ~ TYPE * IF + AUTHOR_CNT + IS_OA + FIRST_AUTHOR_AGE + LAST_AUTHOR_AGE + FIRST_AUTHOR_IS_US + LAST_AUTHOR_IS_US + FIRST_AUTHOR_IS_FEMALE + LAST_AUTHOR_IS_FEMALE + FIRST_AUTHOR_TOP100_INSTITUTE + LAST_AUTHOR_TOP100_INSTITUTE + (1|PREPRINT_DOI), 
                              nAGQ=0, 
                              data = article_altmetrics)
# Log-transformed models
fit_log_full_feeds <- lme4::lmer(log(ALT_FEEDS+1) ~ TYPE * IF + AUTHOR_CNT + IS_OA + FIRST_AUTHOR_AGE + LAST_AUTHOR_AGE + FIRST_AUTHOR_IS_US + LAST_AUTHOR_IS_US + FIRST_AUTHOR_IS_FEMALE + LAST_AUTHOR_IS_FEMALE + FIRST_AUTHOR_TOP100_INSTITUTE + LAST_AUTHOR_TOP100_INSTITUTE + (1|PREPRINT_DOI),
                           REML=F, 
                           data = article_altmetrics)

# Compare AIC - see https://stats.stackexchange.com/questions/48714/prerequisites-for-aic-model-comparison
aic_nb_full_feeds <- AIC(fit_nb_full_feeds)
aic_log_full_feeds <- AIC(fit_log_full_feeds) + (2*sum(log(article_altmetrics$ALT_FEEDS+1)))

# Assess multicollinearity (VIF)
vif_nb_full_feeds <- car::vif(fit_nb_full_feeds)
meanvif_nb_full_feeds <- mean(car::vif(fit_nb_full_feeds))

# Dispersion parameter (theta)
theta_nb_full_feeds <- getME(fit_nb_full_feeds, "glmer.nb.theta")

```

### Regression Analysis: News (MSM)

#### Reduced Models

```{r}
# Negative binomial model
fit_nb_reduced_msm <- lme4::glmer.nb(ALT_MSM ~ TYPE + (1|PREPRINT_DOI), 
                               nAGQ=0, 
                               data = article_altmetrics)
# Log-transformed models
fit_log_reduced_msm <- lme4::lmer(log(ALT_MSM+1) ~ TYPE + (1|PREPRINT_DOI), 
                            REML=F, 
                            data = article_altmetrics)

# Compare AIC - see https://stats.stackexchange.com/questions/48714/prerequisites-for-aic-model-comparison
aic_nb_reduced_msm <- AIC(fit_nb_reduced_msm )
aic_log_reduced_msm <- AIC(fit_log_reduced_msm) + (2*sum(log(article_altmetrics$ALT_MSM+1)))

# Dispersion parameter (theta)
theta_nb_reduced_msm <- getME(fit_nb_reduced_msm , "glmer.nb.theta")
```

#### Full Models

```{r}
# Negative binomial model
fit_nb_full_msm <- lme4::glmer.nb(ALT_MSM ~ TYPE * IF + AUTHOR_CNT + IS_OA + FIRST_AUTHOR_AGE + LAST_AUTHOR_AGE ++ FIRST_AUTHOR_IS_US + LAST_AUTHOR_IS_US + FIRST_AUTHOR_IS_FEMALE + LAST_AUTHOR_IS_FEMALE + FIRST_AUTHOR_TOP100_INSTITUTE + LAST_AUTHOR_TOP100_INSTITUTE + (1|PREPRINT_DOI), 
                              nAGQ=0, 
                              control=glmerControl(optimizer="bobyqa",
                                                   tolPwrss=1e-4,
                                    optCtrl = list(maxfun = 100000)), # optimisation issues, negligible effect on results
                              data = article_altmetrics)
# Log-transformed models
fit_log_full_msm <- lme4::lmer(log(ALT_MSM+1) ~ TYPE * IF + AUTHOR_CNT + IS_OA + FIRST_AUTHOR_AGE + LAST_AUTHOR_AGE + FIRST_AUTHOR_IS_US + LAST_AUTHOR_IS_US + FIRST_AUTHOR_IS_FEMALE + LAST_AUTHOR_IS_FEMALE + FIRST_AUTHOR_TOP100_INSTITUTE + LAST_AUTHOR_TOP100_INSTITUTE + (1|PREPRINT_DOI),
                           REML=F, 
                           data = article_altmetrics)

# Compare AIC - see https://stats.stackexchange.com/questions/48714/prerequisites-for-aic-model-comparison
aic_nb_full_msm <- AIC(fit_nb_full_msm)
aic_log_full_msm <- AIC(fit_log_full_msm) + (2*sum(log(article_altmetrics$ALT_MSM+1)))

# Assess multicollinearity (VIF)
vif_nb_full_msm <- car::vif(fit_nb_full_msm)
meanvif_nb_full_msm <- mean(car::vif(fit_nb_full_msm))

# Dispersion parameter (theta)
theta_nb_full_msm <- getME(fit_nb_full_msm, "glmer.nb.theta")

```

### Regression Analysis: Wikipedia

#### Reduced Models

```{r}
# Negative binomial model
fit_nb_reduced_wikipedia <- lme4::glmer.nb(ALT_WIKIPEDIA ~ TYPE + (1|PREPRINT_DOI), 
                               nAGQ=0, 
                               data = article_altmetrics)
# Log-transformed models
fit_log_reduced_wikipedia <- lme4::lmer(log(ALT_WIKIPEDIA+1) ~ TYPE + (1|PREPRINT_DOI), 
                            REML=F, 
                            data = article_altmetrics)

# Model summaries
summary(fit_nb_reduced_wikipedia)
summary(fit_log_reduced_wikipedia)

# Compare AIC - see https://stats.stackexchange.com/questions/48714/prerequisites-for-aic-model-comparison
aic_nb_reduced_wikipedia <- AIC(fit_nb_reduced_wikipedia)
aic_log_reduced_wikipedia <- AIC(fit_log_reduced_wikipedia) + (2*sum(log(article_altmetrics$ALT_WIKIPEDIA+1)))

# Dispersion parameter (theta)
theta_nb_reduced_wikipedia <- getME(fit_nb_reduced_wikipedia, "glmer.nb.theta")

```

#### Full Models

```{r}
# Negative binomial model
fit_nb_full_wikipedia <- lme4::glmer.nb(ALT_WIKIPEDIA ~ TYPE * IF + AUTHOR_CNT + IS_OA + FIRST_AUTHOR_AGE + LAST_AUTHOR_AGE + FIRST_AUTHOR_IS_US + LAST_AUTHOR_IS_US + FIRST_AUTHOR_IS_FEMALE + LAST_AUTHOR_IS_FEMALE + FIRST_AUTHOR_TOP100_INSTITUTE + LAST_AUTHOR_TOP100_INSTITUTE + (1|PREPRINT_DOI), nAGQ=0, data = article_altmetrics)

# Log-transformed models
fit_log_full_wikipedia <- lme4::lmer(log(ALT_WIKIPEDIA+1) ~ TYPE * IF + AUTHOR_CNT + IS_OA + FIRST_AUTHOR_AGE + LAST_AUTHOR_AGE + FIRST_AUTHOR_IS_US + LAST_AUTHOR_IS_US + FIRST_AUTHOR_IS_FEMALE + LAST_AUTHOR_IS_FEMALE + FIRST_AUTHOR_TOP100_INSTITUTE + LAST_AUTHOR_TOP100_INSTITUTE + (1|PREPRINT_DOI),
                           REML=F, 
                           data = article_altmetrics)

# Compare AIC - see https://stats.stackexchange.com/questions/48714/prerequisites-for-aic-model-comparison
aic_nb_full_wikipedia <- AIC(fit_nb_full_wikipedia)
aic_log_full_wikipedia <- AIC(fit_log_full_wikipedia) + (2*sum(log(article_altmetrics$ALT_WIKIPEDIA+1)))

# Assess multicollinearity (VIF)
vif_nb_full_wikipedia <- car::vif(fit_nb_full_wikipedia)
meanvif_nb_full_wikipedia <- mean(car::vif(fit_nb_full_wikipedia))

# Dispersion parameter (theta)
theta_nb_full_wikipedia <- getME(fit_nb_full_wikipedia, "glmer.nb.theta")
```

### Regression Analysis: Mendeley

#### Reduced Models

```{r}
# Negative binomial model
fit_nb_reduced_mendeley <- lme4::glmer.nb(ALT_MENDELEY ~ TYPE + (1|PREPRINT_DOI), 
                               nAGQ=0, 
                               data = article_altmetrics)
# Log-transformed models
fit_log_reduced_mendeley <- lme4::lmer(log(ALT_MENDELEY+1) ~ TYPE + (1|PREPRINT_DOI), 
                            REML=F, 
                            data = article_altmetrics)

# Compare AIC - see https://stats.stackexchange.com/questions/48714/prerequisites-for-aic-model-comparison
aic_nb_reduced_mendeley <- AIC(fit_nb_reduced_mendeley)
aic_log_reduced_mendeley <- AIC(fit_log_reduced_mendeley) + (2*sum(log(article_altmetrics$ALT_MENDELEY+1)))

# Dispersion parameter (theta)
theta_nb_reduced_mendeley <- getME(fit_nb_reduced_mendeley, "glmer.nb.theta")

```

#### Full Models

```{r}

# Negative binomial model
fit_nb_full_mendeley <- lme4::glmer.nb(ALT_MENDELEY ~ TYPE * IF + AUTHOR_CNT + IS_OA + FIRST_AUTHOR_AGE + LAST_AUTHOR_AGE + FIRST_AUTHOR_IS_US + LAST_AUTHOR_IS_US + FIRST_AUTHOR_IS_FEMALE + LAST_AUTHOR_IS_FEMALE + FIRST_AUTHOR_TOP100_INSTITUTE + LAST_AUTHOR_TOP100_INSTITUTE + (1|PREPRINT_DOI), 
                              nAGQ=0, 
                              data = article_altmetrics)
# Log-transformed models
fit_log_full_mendeley <- lme4::lmer(log(ALT_MENDELEY+1) ~ TYPE * IF + AUTHOR_CNT + IS_OA + FIRST_AUTHOR_AGE + LAST_AUTHOR_AGE + FIRST_AUTHOR_IS_US + LAST_AUTHOR_IS_US + FIRST_AUTHOR_IS_FEMALE + LAST_AUTHOR_IS_FEMALE + FIRST_AUTHOR_TOP100_INSTITUTE + LAST_AUTHOR_TOP100_INSTITUTE + (1|PREPRINT_DOI),
                           REML=F, 
                           data = article_altmetrics)

# Compare AIC - see https://stats.stackexchange.com/questions/48714/prerequisites-for-aic-model-comparison
aic_nb_full_mendeley <- AIC(fit_nb_full_mendeley)
aic_log_full_mendeley <- AIC(fit_log_full_mendeley) + (2*sum(log(article_altmetrics$ALT_MENDELEY+1)))

# Assess multicollinearity (VIF)
vif_nb_full_mendeley <- car::vif(fit_nb_full_mendeley)
meanvif_nb_full_mendeley <- mean(car::vif(fit_nb_full_mendeley))

# Dispersion parameter (theta)
theta_nb_full_mendeley <- getME(fit_nb_full_mendeley, "glmer.nb.theta")

```

#### Calculation of bootstrap confidence intervals

```{r}

# Function for calculation of CI
bootstrapCI <- function(fit, i) {

  # Bootstrap residuals
  boot.out <- lme4::bootMer(fit, FUN=fixef, nsim=i, parallel = "snow", ncpus=2)
  
  # Calculate quantiles of bootstrap output
  quantiles <- apply(boot.out$t, 2, function(x) quantile(x, probs=c(0.025, 0.5, 0.975), na.rm=T))
  
  # Calculate CI around fixed effects
  CI_lower <- fixef(fit) - (quantiles[2,] - quantiles[1,])
  CI_upper <- fixef(fit) + (quantiles[3,] - quantiles[2,])
  
  return(rbind(CI_upper, CI_lower))
}

# Do 1000 bootstrap iterations
iterations <- 1000

# Calcuate CIs for each model
confint_nb_reduced_citations <- bootstrapCI(fit_nb_reduced_citations, iterations)
confint_nb_full_citations <- bootstrapCI(fit_nb_full_citations, iterations)
confint_nb_reduced_tweets <- bootstrapCI(fit_nb_reduced_tweets, iterations)
confint_nb_full_tweets <- bootstrapCI(fit_nb_full_tweets, iterations)
confint_nb_reduced_feeds <- bootstrapCI(fit_nb_reduced_feeds, iterations)
confint_nb_full_feeds <- bootstrapCI(fit_nb_full_feeds, iterations)
confint_nb_reduced_msm <- bootstrapCI(fit_nb_reduced_msm, iterations)
confint_nb_full_msm <- bootstrapCI(fit_nb_full_msm, iterations)
confint_nb_reduced_wikipedia <- bootstrapCI(fit_nb_reduced_wikipedia, iterations)
confint_nb_full_wikipedia <- bootstrapCI(fit_nb_full_wikipedia, iterations)
confint_nb_reduced_mendeley <- bootstrapCI(fit_nb_reduced_mendeley, iterations)
confint_nb_full_mendeley <- bootstrapCI(fit_nb_full_mendeley, iterations)


```

