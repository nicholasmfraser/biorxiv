---
title: "Examining the citation and altmetric advantage of bioRxiv preprints"
output: html_notebook
---

# Initial Configuration --------------------------------------------------------

### Load libraries

```{r results='hide'}

# Call libraries
library(tidyverse)
library(jsonlite)
library(lubridate)
library(httr)
library(stringdist)
library(rcrossref)

# Initial config of libraries
httr::set_config(config(ssl_version=5, ssl_verifypeer=0L, ssl_verifyhost=0L))

```


### Set global variables

```{r results='hide'}

# Credentials for APIs - these should be set in .Renviron file
altmetric_api_key <- Sys.getenv("ALTMETRIC_API_KEY")

# Generate start and end dates of months for period of data extraction
startdates <- seq(ymd("2013-11-1"), ymd("2017-12-01"), by = "months")
enddates <- startdates %m+% months(1) - 1
months <- length(startdates)

```

# Basic Data -------------------------------------------------------------------

### Count number of bioRxiv preprints deposited

```{r results='hide'}

startdate <- startdates[1]
enddate <- enddates[length(enddates)]

# Retrieve total number of preprints
count_all_preprints <- cr_types(types="posted-content", works=TRUE, 
                                facet="publisher-name:*", 
                                filter=c(member = 246, 
                                from_posted_date = as.character(startdate), 
                                until_posted_date = as.character(enddate)),
                                limit=0)$facets$`publisher-name`$V1

# Retrieve number of preprints with a link to a published paper
count_published_preprints <- cr_types(types="posted-content", works=TRUE, 
                                      facet="publisher-name:*", 
                                      filter=c(member = 246, 
                                      relation.type = "is-preprint-of", 
                                      from_posted_date = as.character(startdate), 
                                      until_posted_date = as.character(enddate)),
                                      limit=0)$facets$`publisher-name`$V1

```

### Distribution of bioRxiv preprint deposits over time

```{r results='hide'}

# Retrieve all preprints between two dates
all_preprints <- function(startdate, enddate) {
  count <- cr_types(types="posted-content", works=TRUE, 
                    facet="publisher-name:*", filter=c(member = 246, 
                    from_posted_date = as.character(startdate), 
                    until_posted_date = as.character(enddate)), 
                    limit=0)$facets$`publisher-name`$V1
  return(count)
}

# Retrieve all preprints with a link to a published paper between two dates
published_preprints <- function(startdate, enddate) {
  count <- cr_types(types="posted-content", works=TRUE, 
                    facet="publisher-name:*", filter=c(member = 246, 
                    relation.type = "is-preprint-of", 
                    from_posted_date = as.character(startdate), 
                    until_posted_date = as.character(enddate)), 
                    limit=0)$facets$`publisher-name`$V1
  return(count)
}

# Generate distributions of preprints
preprint_distributions_cr <- tibble(
  "date" = format(as.Date(startdates), "%Y-%m"),
  "preprints" = unlist(map2(startdates, enddates, all_preprints)),
  "matching_preprints" = unlist(map2(startdates, enddates, published_preprints))
)

# Write results to csv
write.csv(preprint_distributions_cr, 
          file="data/preprint_distributions_cr.csv", 
          row.names=FALSE)

# Remove redundant variables
rm(all_preprints, published_preprints, preprint_distributions_cr)

```

# Crossref Metadata Extraction -------------------------------------------------

### Basic metadata for all bioRxiv preprints

```{r results='hide'}

# Retrieve DOI, title, posted (issued) date and authorship for preprints
data <- cr_types(types="posted-content", works=TRUE, 
                 facet="publisher-name:*", filter=c(member = 246, 
                 from_posted_date = as.character(startdate), 
                 until_posted_date = as.character(enddate)), 
                 limit=1000, cursor="*", cursor_max = count_all_preprints, 
                 select=c("DOI", "title", "issued", "author"))$data

# Build data frame
# We only want to keep the family name of the first author
preprints_metadata_cr <- tibble(
  "cr_preprint_doi" = as.character(data$doi),
  "cr_preprint_title" = as.character(data$title),
  "cr_preprint_posted" = as.character(data$issued),
  "cr_preprint_author" = as.character(map(data$author, function(x) x$family[1]))
)

# Write results to csv
write.csv(preprints_metadata_cr, 
          file="data/preprints_cr.csv", 
          row.names=FALSE)

# Remove redundant variables
rm(data)

```

### DOI links between preprints and published papers via Crossref

```{r results='hide'}

# To retrieve relationships, we use the rcrossref low level API (cr_types_)
data <- cr_types_(types="posted-content", works=TRUE, 
                  filter=c(member = 246, relation.type = "is-preprint-of", 
                  from_posted_date = as.character(startdate), 
                  until_posted_date = as.character(enddate)), 
                  cursor="*", limit=1000, cursor_max=count_published_preprints, 
                  parse=TRUE, select=c("DOI", "relation", "issued"))

# Extract individual items
items <- unlist(sapply(data, function(x) x$message$items), recursive=FALSE)

# Build data frame
preprints_published_articles_cr <- tibble(
  "cr_preprint_doi" = sapply(items, function(x) x$DOI),
  "cr_preprint_posted" = sapply(items, 
                                function(x) paste0(x$issued$`date-parts`[[1]][1], 
                                "-", x$issued$`date-parts`[[1]][2], 
                                "-", x$issued$`date-parts`[[1]][3])),
  "cr_published_doi" = sapply(items, function(x) x$relation$`is-preprint-of`[[1]]$id)
)

# Clean data. For duplicates, we keep only the earliest dated version
preprints_published_articles_cr <- preprints_published_articles_cr %>%
  arrange(cr_published_doi, cr_preprint_posted) %>%
  group_by(cr_published_doi) %>%
  slice(1) %>%
  ungroup()

# We want to match our preprints data with titles of published articles
data <- cr_works_(dois=published_dois, .progress="text", parse=TRUE)

# Create data frame of published articles. Remove duplicates and NULL values
published_articles <- tibble(
  "cr_published_doi" = tolower(as.character(map(data, function(x) x$message$DOI))),
  "cr_published_title" = tolower(as.character(map(data, function(x) x$message$title[[1]])))
) %>% distinct() %>% filter(cr_published_title != "NULL")

# Set lowercase doi for matching
preprints_published_articles_cr <- preprints_published_articles_cr %>%
  mutate(cr_published_doi = tolower(cr_published_doi))

# Join relationship and title data
preprints_published_articles_cr <- inner_join(preprints_published_articles_cr, 
                                              published_articles, 
                                              by=c("cr_published_doi"))

# Write results to csv
write.csv(preprints_published_articles_cr, 
          file="data/preprints_published_articles_cr.csv", 
          row.names=FALSE)

rm(data, items, published_articles)

```

# Fuzzy WoS Matching of Preprints ----------------------------------------------

### Clean and Prepare data for matching

```{r results='hide'}

# Select columns, remove whitespace and line breaks
cr_published_wos_matching <- preprints_published_articles_cr %>%
  select(cr_preprint_doi, cr_published_doi, cr_published_title) %>%
  mutate(cr_published_doi = gsub("[\r\n]", "", cr_published_doi), 
         cr_published_title = gsub("[\r\n]", "", cr_published_title)) %>% 
  mutate(cr_published_doi = str_trim(cr_published_doi), cr_published_title = str_trim(cr_published_title)) 

# Write results to csv
write.csv(cr_published_wos_matching, 
          file="data/KB/input/cr_published_wos_matching.csv", 
          row.names=FALSE)

# Remove redundant variables
rm(cr_published_wos_matching)

```

### Crossref data is matched to WoS records in KB database on DOIs and titles

Input: data/KB/input/cr_published_wos_matching.csv -> BIORXIV_CR_PUBLISHED
SQL:cr_published_wos_matching.sql
Output: data/KB/output/cr_published_wos_matched.csv

### Clean resulting data

```{r}

# Load data and keep only non-duplicated items
cr_published_wos_matched <- read_csv(file="data/KB/output/cr_published_wos_matched.csv") %>%
  group_by(CR_PUBLISHED_DOI) %>% 
  filter(n() == 1) %>%
  ungroup()

```

### Relationships between published articles and preprints in Crossref are incomplete. 
### Preprints that do not have a relationship in Crossref are matched to 
### WoS articles via fuzzy matching of titles and first names

### Clean and prepare preprint data to be matched

```{r results='hide'}

preprints_metadata_cr <- read_csv(file="data/preprints_cr.csv")

# Subset preprints without a matching paper in Crossref for WoS matching
cr_preprints_wos_matching <- preprints_metadata_cr %>%
  filter(!cr_preprint_doi %in% cr_published_wos_matched$CR_PREPRINT_DOI) %>%
  mutate(cr_preprint_posted_year = year(as.Date(cr_preprint_posted))) %>%
  mutate(cr_preprint_title = tolower(cr_preprint_title)) %>% 
  mutate(cr_preprint_author = tolower(cr_preprint_author)) %>%
  mutate(cr_preprint_doi = gsub("[\r\n]", "", cr_preprint_doi), 
         cr_preprint_title = gsub("[\r\n]", "", cr_preprint_title), 
         cr_preprint_author = gsub("[\r\n]", "", cr_preprint_author)) %>% 
  mutate(cr_preprint_doi = str_trim(cr_preprint_doi), 
         cr_preprint_title = str_trim(cr_preprint_title), 
         cr_preprint_author = str_trim(cr_preprint_author)) %>% 
 select(cr_preprint_doi, cr_preprint_title, cr_preprint_author, cr_preprint_posted_year)
  
# Write results to csv
write.csv(cr_preprints_wos_matching, file="data/KB/input/cr_preprints_wos_matching.csv", row.names=FALSE)

rm(cr_preprints_wos_matching)
```

### We retrieve all articles with the same author last name, 
### published after the date of preprint deposition

Input:data/KB/input/cr_preprints_wos_matching.csv -> BIORXIV_CR_PREPRINTS
SQL: cr_preprints_wos_matching.sql
Output: data/KB/output/cr_preprints_wos_matched.csv

### Fuzzy matching of returned WoS articles to unmatched preprints

```{r results='hide'}

# Read data of WoS articles. CAUTION: Large file
wos_articles <- read_csv(file="data/KB/output/cr_preprints_wos_matched.csv", 
                         col_names=TRUE)

# Prepare data for matching - set columns to lowercase and remove duplicates
wos_articles <- wos_articles %>%
  mutate(LASTNAME = tolower(LASTNAME)) %>%
  mutate(ARTICLE_TITLE = tolower(ARTICLE_TITLE)) %>%
  filter(!PK_ITEMS %in% cr_published_wos_matched$PK_ITEMS) 

# Fuzzy matching function. Returns best article match and the matching accuracy
getMatch <- function(item) {
  
  # Filter WoS articles for author and year
  w <- wos_articles %>%
    filter(LASTNAME == item["cr_preprint_author"]) %>%
    filter(PUBYEAR >= item["cr_preprint_posted_year"])
  
  if(!length(w$LASTNAME)){
    return(NA)
  } else {
    # Fuzzy match (method "jw" = Jaro-Winkler distance)
    # Can experiment with similarity percentage (inverse of maxDist). 
    # 80% (maxDist=0.2) seems to be good. 
    # Below 70% results in too many false positives
    index <- amatch(item["cr_preprint_title"], 
                    w$ARTICLE_TITLE, 
                    method="jw", 
                    nomatch = NA_integer_, 
                    maxDist = 0.2)
    if(is.na(index)) {
      return(NA)
    } else {
      match <- w[index,]
      match["cr_preprint_doi"] <- item["cr_preprint_doi"]
      match["cr_preprint_title"] <- item["cr_preprint_title"]
      match["match_accuracy"] <- stringdist(item["cr_preprint_title"], 
                                            match$ARTICLE_TITLE, 
                                            method="jw")
      return(match)
    }
  }
}

# Match preprint titles to articles in Web of Science
matches <- apply(cr_preprints_wos_matching, 1, getMatch)
matches <- matches[lapply(matches, length) > 1]

# Clean data and remove any duplicates
cr_preprints_wos_matched <- map_dfr(matches, function(x) x) %>% 
  select(-c("LASTNAME")) %>%
  group_by(PK_ITEMS) %>% 
  filter(n() == 1) %>% # remove duplicates
  ungroup()

rm(wos_articles, getMatch, matches)

```

### Merge two datasets (crossref-matched and fuzzy-matched) together

```{r results='hide'}

cr_preprints_wos_matched <- cr_preprints_wos_matched %>% 
  select(-c("cr_preprint_title")) %>%
  rename(CR_PREPRINT_DOI = cr_preprint_doi)

cr_published_wos_matched <- cr_published_wos_matched %>% 
  select(-c("CR_PUBLISHED_DOI", "CR_PUBLISHED_TITLE"))

published_articles <- bind_rows(cr_published_wos_matched, cr_preprints_wos_matched)

write.csv(published_articles, file="data/published_articles.csv", row.names=FALSE)

rm(cr_published_wos_matched, cr_preprints_wos_matched)

```

# Generating a Control Dataset -------------------------------------------------

### Retrieve category information for articles in published dataset

Input: data/published_articles.csv -> TABLE BIORXIV_PUBLISHED_FINAL
SQL Query: sql/published_article_categories.sql
Output: data/KB/output/published_article_categories.csv

### Split categories into single and multidisciplinary groups:

```{r results='hide'}

# Read data
categories <- read_csv("data/KB/output/published_article_categories.csv")

# Split into single disciplinary and multidisciplinary categories
single_cat <- categories %>%
  filter(PK_CLASSIFICATIONS != 111)

multi_cat <- categories %>%
  filter(PK_CLASSIFICATIONS == 111) %>%
  filter(!PK_ITEMS %in% single_cat$PK_ITEMS)

write.csv(single_cat, 
          file="data/KB/input/published_single_category.csv", 
          row.names=FALSE)
write.csv(multi_cat, 
          file="data/KB/input/published_multi_category.csv", 
          row.names=FALSE)

rm(categories)

```

### Handle single disciplinary articles

### First retrieve all articles from the same journal-issues from WoS

Input: data/KB/input/published_single_category.csv -> TABLE BIORXIV_SINGLE_CAT
SQL Query: published_control_single_category.sql
Output: data/KB/output/control_single_category.csv

### Select a single random article as the matching article

```{r results='hide'}

control_data <- read_csv("data/KB/output/control_single_category.csv") %>%
  filter(!PK_ITEMS %in% single_cat$PK_ITEMS) # remove items associated with bioRxiv articles

single_cat <- single_cat %>%
  distinct(PK_ITEMS, .keep_all=T) %>%
  left_join(control_data, by = "FK_ISSUES") %>% 
  group_by(PK_ITEMS.x) %>%
  sample_n(1) %>%
  ungroup()

rm(control_data)

```

### Handle multi disciplinary articles

### First retrieve categories of articles cited by multidisciplinary published articles

Input: data/KB/input/published_multi_category.csv -> TABLE BIORXIV_MULTI_CAT
SQL Query: published_multidisciplinary_categories.sql
Output: data/KB/output/published_multidisciplinary_categories.sql.csv

### Then retrieve articles published in the same journal issues, and the categories of articles they cite

Input: data/KB/input/published_multi_category.csv -> TABLE BIORXIV_MULTI_CAT
SQL Query: published_control_multidisciplinary_categories.sql
Output: data/KB/output/control_multidisciplinary_categories.csv

### Multidisciplinary published articles are matched to a category based on the most frequently cited category amongst their references. A single, random article is then selected from the control articles in the same category and journal-issue

```{r results='hide'}

published_data <- read_csv("data/KB/output/published_multidisciplinary_categories.csv")

control_data <- read_csv("data/KB/output/control_multidisciplinary_categories.csv")

published_distinct <- published_data %>%
  distinct(PK_ITEMS)

published_categories <- published_data %>%
  filter(CLASSIFICATION_1 != "Multidisciplinary Sciences") %>%
  group_by(PK_ITEMS, FK_ISSUES) %>% 
  count(CLASSIFICATION_1) %>% 
  rename(CLASSIFICATION = CLASSIFICATION_1) %>%
  top_n(1) %>%
  ungroup

control_distinct <- control_data %>%
  distinct(PK_ITEMS)

control_categories <- control_data %>% 
  filter(CLASSIFICATION != "Multidisciplinary Sciences") %>%
  filter(PK_ITEMS %in% published_categories$PK_ITEMS) %>%
  group_by(PK_ITEMS, FK_ISSUES) %>%
  count(CLASSIFICATION) %>% 
  top_n(1) %>%
  ungroup

matches <- left_join(published_categories, control_categories, by=c("FK_ISSUES", "CLASSIFICATION")) %>%
  group_by(PK_ITEMS.x) %>%
  arrange(desc(n.y)) %>%
  top_n(1) %>%
  sample_n(1)


```

### Clean and merge single and multidisciplinary datasets

```{r results='hide'}

```

### Retrieve Crossref publication dates for all items and finalize datasets

```{r results='hide'}

```


### Retrieve citing articles

Published articles:
Input:
SQL Query:
Output:

Control articles:
Input:
SQL Query:
Output: 


### Retrieve Crossref publication dates for citing items

```{r results='hide'}

```

